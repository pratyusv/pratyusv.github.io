<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Y5BVSQVXNK"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-Y5BVSQVXNK');
</script>        
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Pratyush | Design Web Crawler</title>
    <meta name="author" content="Pratyush  Varshney" />
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://pratyusv.github.io/blog/2022/webcrawler/">

    <!-- Dark Mode -->
    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
  </head>

  <!-- Body -->
  <body class="fixed-top-nav">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://pratyusv.github.io/">Pratyush</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <!-- <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog</a>
              </li> -->
              <!-- vitae -->
              <li class="nav-item ">
                <a class="nav-link" href="/assets/pdf/PratyushVarshney.pdf">vitae</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/resources/">resources</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/tech/">tech</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Design Web Crawler</h1>
    <p class="post-meta">January 15, 2022</p>
    <p class="post-tags">
      <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>
        ·  
        <a href="/blog/category/System%20Design">
          <i class="fas fa-tag fa-sm"></i> System Design</a>  
          

    </p>
  </header>

  <article class="post-content">
    <p>Features to support:</p>

<ol>
  <li>Politeness/crawl rate: respect the upper limit of visit frequency of sites</li>
  <li>DNS Query</li>
  <li>Distributed Crawling</li>
  <li>Priority Crawling</li>
  <li>Duplication Crawling</li>
</ol>

<hr>

<h3 id="capacity-estimation">Capacity Estimation</h3>

<p>Consider total web pages: <code class="language-plaintext highlighter-rouge">15 Billion</code></p>

<p>We can crawl those pages in one month:</p>
<blockquote>
  <p>15 billion * (4 weeks * 7 days * 86400 seconds) ~ 6200 pages/sec</p>
</blockquote>

<ul>
  <li>Assume the size of each page: <code class="language-plaintext highlighter-rouge">100 KB</code>
</li>
  <li>Metadata size: <code class="language-plaintext highlighter-rouge">500 bytes per page</code>
</li>
</ul>

<p>Total size:</p>
<blockquote>
\[15 * 10^9 pages * (100 * 10^3 + 500) bytes \rightarrow 1.5 * 10^{15} \rightarrow 1.5 PB\]
</blockquote>

<p>We assume that our storage is only <code class="language-plaintext highlighter-rouge">70%</code> consumed</p>

<blockquote>
  <p>1.5 PB / 0.7 ~ 2.14 PB</p>
</blockquote>

<hr>

<h3 id="high-level-design">High-Level Design</h3>

<ol>
  <li>Pick a URL from the unvisited URL list</li>
  <li>Determine the IP address of the URL</li>
  <li>Connect with the host and download the content</li>
  <li>Parse the content and filter the URLs</li>
  <li>Add the new URLs to the unvisited list</li>
  <li>Process the downloaded content: store or index its content</li>
</ol>

<hr>

<h2 id="architecture">Architecture</h2>

<p><br>
<br></p>

<div>
    <center><img src="/assets/img/webcrawler/architecture.png"></center>
</div>

<hr>

<h2 id="services">Services</h2>

<ol>
  <li>
    <p><strong>Seed URLs</strong>: The list of URLs from which the web crawler will start to crawl the web pages. This can be a list of highly visited sites like yahoo, google, CNN, etc.</p>
  </li>
  <li>
    <p><strong>URL Frontier</strong>: URL Frontier contains the list of URLs that are not visited yet by the crawler.</p>
  </li>
  <li>
<strong>Fetcher+Renderer</strong>:
    <ul>
      <li>Multithreaded set of a cluster that fetches the web pages from the web.</li>
      <li>Pages are generally not static. There are generally scripts like JS, Ajax on the web pages. Therefore a renderer is required that executes these scripts on the server-side to generate the complete webpage.</li>
    </ul>
  </li>
  <li>
<strong>DNS Resolver</strong>:
    <ul>
      <li>To fetch a document, Hostnames need to be mapped to IP address.</li>
      <li>For the IP lookup instead of sending a request to an external DNS server, an internal resolver can be used to reduce the latency.</li>
    </ul>
  </li>
  <li>
<strong>Document Input Stream</strong>:
    <ul>
      <li>Threads forward the downloaded document to Document Input Stream.</li>
      <li>Document is cached in a <code class="language-plaintext highlighter-rouge">Redis</code> cluster for further processing</li>
      <li>The document is processed for duplication checks and compressed and stored in a database like <code class="language-plaintext highlighter-rouge">BigTable</code>
</li>
      <li>
<strong>Document De-dupe Module</strong>:
        <ul>
          <li>The document is checked whether its content has been previously seen.</li>
          <li>If the document is previously seen it is discarded and not stored.</li>
          <li>If this is a fresh document, it is compressed and stored in the database.</li>
          <li>Fingerprint mechanisms like <code class="language-plaintext highlighter-rouge">checksum</code> or <code class="language-plaintext highlighter-rouge">shingles</code> can be used to detect duplication</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
<strong>URL Extractor</strong>:
    <ul>
      <li>A copy of the document from the <code class="language-plaintext highlighter-rouge">Redis</code> cache is fed to the extractor.</li>
      <li>The extractor will parse the network protocol and extract all the links.</li>
      <li>The links are converted to absolute URLs.</li>
    </ul>
  </li>
  <li>
<strong>URL Filter</strong>:
    <ul>
      <li>The URL filter provides a customizable mechanism for controlling the URLs to be crawled.</li>
      <li>The crawler can be restricted to crawl on certain formats like jpg, png, etc. while discarding formats like mp3, etc.</li>
      <li>The robot exclusion protocol restricts the web pages for a crawler. This can be done by the URL filter.</li>
    </ul>
  </li>
  <li>
<strong>URL De-dupe test</strong>:
    <ul>
      <li>Most of the pages contain URLs that are already seen by the crawler.</li>
      <li>Already crawled URLs can be maintained in a data store based on the domain name.</li>
      <li>The duplication test can be either done by checking the checksum instead of string comparison or using Bloom filters.</li>
    </ul>
  </li>
</ol>

<hr>

<h2 id="prioritization-and-politeness">Prioritization and Politeness</h2>

<p>The prioritization and politeness are implemented in the URL Frontier module as it provides the list of URLs to the fetchers. Priority of webpages can be decided by:</p>
<ol>
  <li>quality of the webpage</li>
  <li>rate of change of webpage</li>
</ol>

<p>Spam webpages change their contents frequently that is why we also need to check the quality of the webpages. For a news page that updates content frequently, the crawler will need to recrawl the link every few minutes to incorporate any changes.</p>

<h3 id="politeness">Politeness</h3>

<ul>
  <li>Crawler should ensure that it does not overwhelm the host’s server at any point in time</li>
  <li>Single connection should be open between host and crawler</li>
</ul>

<div>
    <center><img src="/assets/img/webcrawler/frontier.png"></center>
</div>

<p><br></p>

<p>Two queues are maintained by the URL frontier.</p>

<ul>
  <li>
<strong>Front Queue</strong>:
    <ul>
      <li>They implement the prioritization.</li>
      <li>Number of front queues depends on the prioritization. For now, we assume there are F front queues.</li>
    </ul>
  </li>
  <li>
<strong>Back Queue</strong>:
    <ul>
      <li>They implement politeness.</li>
      <li>The number of back queues depends upon the number of threads running in the fetcher. Every queue is mapped to one and only one thread.</li>
      <li>Each back queue can contain URLs from a single domain only. This ensures that the thread responsible for that queue will open only one connection with the host.</li>
    </ul>
  </li>
</ul>

<p><strong>Biased Front Queues Selector</strong>:</p>
<ul>
  <li>The URLs are pushed from the front queue to the back queue by the selector. It is biased as it picks the highest priority URLs</li>
</ul>

<p><strong>Back Queue Table</strong>:</p>
<ul>
  <li>Back Queue table is maintained to map the Hostname with the queue number</li>
  <li>When the back queue becomes empty, the biased front queues selector picks up URLs from a different domain and inserts them into the back queue. The queue table is updated with the new hostname.</li>
</ul>

<p><strong>Back Queue Heap</strong>:</p>
<ul>
  <li>Each back queue has a min-heap maintained.</li>
  <li>The priority of the heap is according to the politeness (next visit time)
    <ul>
      <li>for every visit to the host by the crawler, it updates the next visit time according to the politeness and inserts it into a heap.</li>
    </ul>
  </li>
  <li>When the fetcher is done with a URL it asks for the next URL from the Back queue selector. The back queue selector picks up the queue number from the min-heap whose time has to visit has elapsed.</li>
  <li>This helps the crawler in respecting the politeness of the host</li>
</ul>

  </article>

  
  <div id="disqus_thread"></div>
  <script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://https-pratyusv-github-io.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener noreferrer">comments powered by Disqus.</a>
</noscript>
  <a href="http://disqus.com" class="dsq-brlink" target="_blank" rel="noopener noreferrer">comments powered by <span class="logo-disqus">Disqus</span></a>
  
</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Pratyush  Varshney. Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <!-- jQuery -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

    <!-- Mansory & imagesLoaded -->
  <script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
  <script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/mansory.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', '');
  </script>

    
  </body>

</html>

